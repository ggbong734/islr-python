{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISLR Chapter 5 Resampling Methods\n",
    "\n",
    "## Lab Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "references:\n",
    "JWarmenhoven: https://github.com/JWarmenhoven/ISLR-python/blob/master/Notebooks/\n",
    "collinprather: https://github.com/collinprather/ISLR-Python\n",
    "Jliu: https://github.com/0liu/ISLR\n",
    "http://www.science.smith.edu/~jcrouser/SDS293/labs/lab7-py.html\n",
    "'''\n",
    "\n",
    "# Math and data processing\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import scale, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Visulization\n",
    "from IPython.display import display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.1 Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 392 entries, 0 to 396\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           392 non-null    float64\n",
      " 1   cylinders     392 non-null    int64  \n",
      " 2   displacement  392 non-null    float64\n",
      " 3   horsepower    392 non-null    float64\n",
      " 4   weight        392 non-null    int64  \n",
      " 5   acceleration  392 non-null    float64\n",
      " 6   year          392 non-null    int64  \n",
      " 7   origin        392 non-null    int64  \n",
      " 8   name          392 non-null    object \n",
      "dtypes: float64(4), int64(4), object(1)\n",
      "memory usage: 30.6+ KB\n"
     ]
    }
   ],
   "source": [
    "auto = pd.read_csv('Auto.csv', na_values='?').dropna()\n",
    "auto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge rampage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0    18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1    15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2    18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3    16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4    17.0          8         302.0       140.0    3449          10.5    70   \n",
       "..    ...        ...           ...         ...     ...           ...   ...   \n",
       "392  27.0          4         140.0        86.0    2790          15.6    82   \n",
       "393  44.0          4          97.0        52.0    2130          24.6    82   \n",
       "394  32.0          4         135.0        84.0    2295          11.6    82   \n",
       "395  28.0          4         120.0        79.0    2625          18.6    82   \n",
       "396  31.0          4         119.0        82.0    2720          19.4    82   \n",
       "\n",
       "     origin                       name  \n",
       "0         1  chevrolet chevelle malibu  \n",
       "1         1          buick skylark 320  \n",
       "2         1         plymouth satellite  \n",
       "3         1              amc rebel sst  \n",
       "4         1                ford torino  \n",
       "..      ...                        ...  \n",
       "392       1            ford mustang gl  \n",
       "393       2                  vw pickup  \n",
       "394       1              dodge rampage  \n",
       "395       1                ford ranger  \n",
       "396       1                 chevy s-10  \n",
       "\n",
       "[392 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the method to split data employed by jcrouser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative method to split data into test train sets, total rows is 392, so by sampling 196 points we create 50:50 split\n",
    "train_df = auto.sample(196, random_state = 1)\n",
    "test_df = auto[~auto.isin(train_df)].dropna(how = 'all')\n",
    "\n",
    "X_train = train_df['horsepower'].values.reshape(-1,1)\n",
    "y_train = train_df['mpg']\n",
    "X_test = test_df['horsepower'].values.reshape(-1,1)\n",
    "y_test = test_df['mpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the method to split data used by jliu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLR MSE =  25.273723992970933\n"
     ]
    }
   ],
   "source": [
    "# Simple linear regression features and response\n",
    "features = ['horsepower']\n",
    "response = ['mpg']\n",
    "X = auto[features]\n",
    "y = auto[response]\n",
    "\n",
    "# Split Auto data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=196, random_state=47) #using sklearn built-in functions\n",
    "\n",
    "# Regression\n",
    "auto_slr = LinearRegression()\n",
    "auto_slr.fit(X_train, y_train)\n",
    "\n",
    "# Prediction and MSE\n",
    "y_pred = auto_slr.predict(X_test)\n",
    "print(\"SLR MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated test MSE for the linear regression fit is 23.36. We can use the  PolynomialFeatures()  function to estimate the test error for the polynomial and cubic regressions. PolynomialFeatures() generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial regression of degree 2: MSE =  18.869003119495538\n"
     ]
    }
   ],
   "source": [
    "# Polynomial regression features of degree 2\n",
    "poly2 = PolynomialFeatures(degree=2)\n",
    "X2 = poly2.fit_transform(X)\n",
    "\n",
    "# Split Auto data into train and test sets\n",
    "X2_train, X2_test, y_train, y_test = train_test_split(X2, y, test_size=196, random_state=47)\n",
    "a\n",
    "# Regression\n",
    "auto_poly2 = LinearRegression()\n",
    "auto_poly2.fit(X2_train, y_train)\n",
    "\n",
    "# Prediction and MSE\n",
    "y2_pred = auto_poly2.predict(X2_test)\n",
    "print(\"Polynomial regression of degree 2: MSE = \", mean_squared_error(y_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial regression of degree 3: MSE =  18.833366995930167\n"
     ]
    }
   ],
   "source": [
    "# Polynomial regression features of degree 3\n",
    "poly3 = PolynomialFeatures(degree=3)\n",
    "X3 = poly3.fit_transform(X)\n",
    "\n",
    "# Split Auto data into train and test sets\n",
    "X3_train, X3_test, y_train, y_test = train_test_split(X3, y, test_size=196, random_state=47)\n",
    "\n",
    "# Regression\n",
    "auto_poly3 = LinearRegression()\n",
    "auto_poly3.fit(X3_train, y_train)\n",
    "\n",
    "# Prediction and MSE\n",
    "y3_pred = auto_poly3.predict(X3_test)\n",
    "print(\"Polynomial regression of degree 3: MSE = \", mean_squared_error(y_test, y3_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are consistent with our previous findings: a model that predicts  mpg  using a quadratic function of  horsepower  performs better than a model that involves only a linear function of  horsepower , and there is little evidence in favor of a model that uses a cubic function of  horsepower ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.2 Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial regression of degree 1:\n",
      "  MSE = 24.231513517929226\n",
      "\n",
      "\n",
      "Polynomial regression of degree 2:\n",
      "  MSE = 19.248213124489396\n",
      "\n",
      "\n",
      "Polynomial regression of degree 3:\n",
      "  MSE = 19.334984064133813\n",
      "\n",
      "\n",
      "Polynomial regression of degree 4:\n",
      "  MSE = 19.424430309411886\n",
      "\n",
      "\n",
      "Polynomial regression of degree 5:\n",
      "  MSE = 19.033211842978396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Polynomial regression over degrees from 1 (simple linear) to 5\n",
    "auto_poly = LinearRegression()\n",
    "loocv = LeaveOneOut()\n",
    "\n",
    "for poly_deg in range(1, 6):\n",
    "    print(\"\\nPolynomial regression of degree {}:\".format(poly_deg))\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=poly_deg)\n",
    "    X_d = poly.fit_transform(X)\n",
    "    scores = cross_val_score(auto_poly, X_d, y, cv=loocv, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    loocv_mse = scores.mean() * (-1)  # sign-flip to convert score to MSE\n",
    "    print('  MSE = {}\\n'.format(loocv_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a sharp drop in the estimated test MSE between the linear and quadratic fits, but then no clear improvement from using higher-order polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.3 k-Fold Cross-Validation\n",
    "\n",
    "The KFold function can (intuitively) also be used to implement k-fold CV. Below we use k = 10, a common choice for k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggbong/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial regression of degree 1:\n",
      "  MSE = 27.439933652339864\n",
      "\n",
      "\n",
      "Polynomial regression of degree 2:\n",
      "  MSE = 21.23584005580211\n",
      "\n",
      "\n",
      "Polynomial regression of degree 3:\n",
      "  MSE = 21.336606183328694\n",
      "\n",
      "\n",
      "Polynomial regression of degree 4:\n",
      "  MSE = 21.353886994209773\n",
      "\n",
      "\n",
      "Polynomial regression of degree 5:\n",
      "  MSE = 20.905646119059934\n",
      "\n",
      "\n",
      "Polynomial regression of degree 6:\n",
      "  MSE = 20.82189095906726\n",
      "\n",
      "\n",
      "Polynomial regression of degree 7:\n",
      "  MSE = 20.953534894379217\n",
      "\n",
      "\n",
      "Polynomial regression of degree 8:\n",
      "  MSE = 21.077131510426256\n",
      "\n",
      "\n",
      "Polynomial regression of degree 9:\n",
      "  MSE = 21.03675183384266\n",
      "\n",
      "\n",
      "Polynomial regression of degree 10:\n",
      "  MSE = 20.981013741561554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Polynomial regression over degrees from 1 (simple linear) to 10\n",
    "auto_poly = LinearRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=47, shuffle=False)\n",
    "\n",
    "for poly_deg in range(1, 11):\n",
    "    print(\"\\nPolynomial regression of degree {}:\".format(poly_deg))\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=poly_deg)\n",
    "    X_d = poly.fit_transform(X)\n",
    "    scores = cross_val_score(auto_poly, X_d, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    loocv_mse = scores.mean() * (-1)  # sign-flip to convert score to MSE\n",
    "    print('  MSE = {}\\n'.format(loocv_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the computation time is much shorter than that of LOOCV. (In principle, the computation time for LOOCV for a least squares linear model should be faster than for k-fold CV, due to the availability of the formula (5.2) for LOOCV; however, unfortunately the KFold() function does not make use of this formula.) We still see little evidence that using cubic or higher-order polynomial terms leads to lower test error than simply using a quadratic fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.4 The Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.895251</td>\n",
       "      <td>-0.234924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.562454</td>\n",
       "      <td>-0.885176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417090</td>\n",
       "      <td>0.271888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.044356</td>\n",
       "      <td>-0.734198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.315568</td>\n",
       "      <td>0.841983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.479091</td>\n",
       "      <td>1.454774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.535020</td>\n",
       "      <td>-0.399175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.773129</td>\n",
       "      <td>-0.957175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.403634</td>\n",
       "      <td>1.396038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.588496</td>\n",
       "      <td>-0.497285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X         Y\n",
       "0  -0.895251 -0.234924\n",
       "1  -1.562454 -0.885176\n",
       "2  -0.417090  0.271888\n",
       "3   1.044356 -0.734198\n",
       "4  -0.315568  0.841983\n",
       "..       ...       ...\n",
       "95  0.479091  1.454774\n",
       "96 -0.535020 -0.399175\n",
       "97 -0.773129 -0.957175\n",
       "98  0.403634  1.396038\n",
       "99 -0.588496 -0.497285\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio = pd.read_csv('Portfolio.csv')\n",
    "portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio alpha =  0.57583207459283\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the alpha for portfolio allocation\n",
    "def alpha(data):\n",
    "    \"\"\"\n",
    "    data: pandas dataframe with two columns X and Y.\n",
    "    \"\"\"\n",
    "\n",
    "    sigma = data.cov()  # covariance matrix\n",
    "    var_x = sigma.X['X'] # select column X and row X\n",
    "    var_y = sigma.Y['Y']\n",
    "    cov_xy = sigma.X['Y']\n",
    "    alpha = (var_y - cov_xy) / (var_x + var_y - 2 * cov_xy)\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "alpha_original = alpha(portfolio)\n",
    "print(\"Portfolio alpha = \", alpha_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>bias</th>\n",
       "      <th>std. error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>0.575832</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.089929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       original      bias  std. error\n",
       "alpha  0.575832  0.001963    0.089929"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bootstrap with B=1000 on portfolio data\n",
    "N = portfolio.shape[0]\n",
    "B = 1000 #bootstrap samples\n",
    "\n",
    "portfolio_b = resample(portfolio, n_samples=N*B, random_state=42) # create 1000 (B) bootstrap samples of size N each\n",
    "alphas = [alpha(group) for name, group in portfolio_b.groupby(np.arange(N * B) // N)] # group by every 1000 points to generate a list of 1000 alphas\n",
    "\n",
    "alpha_bias = np.mean(alphas) - alpha_original #bias compared to actual\n",
    "alpha_se = np.std(alphas)  #error of alpha\n",
    "\n",
    "alpha_bootstrap = pd.DataFrame([[alpha_original, alpha_bias, alpha_se],],\n",
    "                              columns=['original', 'bias', 'std. error'], index=['alpha'])\n",
    "\n",
    "display(alpha_bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing with jliu bootstrap method, need to **create a function that extracts linear regression coefficient from each bootstrap sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mpg ~ horsepower coefficients:\n",
      "\n",
      "   Intercept  horsepower\n",
      "  39.935861   -0.157845\n"
     ]
    }
   ],
   "source": [
    "# Function to get simple linear regression coefficients for Auto data set\n",
    "def auto_coef(data, features, response):\n",
    "    \"\"\"\n",
    "    data: pandas dataframe sampled from the Auto data set\n",
    "    features: a string list of feature names\n",
    "    response: a string of response names\n",
    "    \"\"\"\n",
    "\n",
    "    auto_reg = LinearRegression()\n",
    "    auto_reg.fit(data[features], data[response])\n",
    "    return [auto_reg.intercept_] + list(auto_reg.coef_)\n",
    "\n",
    "features = ['horsepower']\n",
    "response = 'mpg'\n",
    "coef_original = pd.DataFrame([auto_coef(auto, features, response)], columns=['Intercept'] + features, index=[''])\n",
    "print(\"\\nmpg ~ horsepower coefficients:\\n\\n\", coef_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>bias</th>\n",
       "      <th>std. error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>39.935861</td>\n",
       "      <td>0.033521</td>\n",
       "      <td>0.869087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.157845</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>0.007503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             original      bias  std. error\n",
       "Intercept   39.935861  0.033521    0.869087\n",
       "horsepower  -0.157845 -0.000500    0.007503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bootstrap with B=1000 on Auto data\n",
    "N = auto.shape[0]\n",
    "B = 1000\n",
    "auto_b = resample(auto, n_samples=N*B, random_state=42)\n",
    "coefs = [auto_coef(group, features, response) for name, group in auto_b.groupby(np.arange(N * B) // N)]\n",
    "coefs_df = pd.DataFrame(coefs, columns=['Intercept'] + features)\n",
    "coef_bias = coefs_df.mean() - coef_original\n",
    "coef_se = coefs_df.std()\n",
    "coef_bootstrap = pd.concat([coef_original.T.copy(), coef_bias.T, coef_se], axis=1)\n",
    "coef_bootstrap.columns = ['original', 'bias', 'std. error']\n",
    "display(coef_bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('Auto.csv', na_values='?').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15784473] 39.93586102117047\n"
     ]
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "X = auto['horsepower'].values.reshape(-1,1)\n",
    "y = auto['mpg']\n",
    "clf = lm.fit(X,y)\n",
    "print(clf.coef_, clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 38.73686745681643 Coef: [-0.14596684]\n"
     ]
    }
   ],
   "source": [
    "Xsamp, ysamp = resample(X, y, n_samples=1000)\n",
    "clf = lm.fit(Xsamp,ysamp)\n",
    "print('Intercept: ' + str(clf.intercept_) + \" Coef: \" + str(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsamp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approach to Bootstrap by jrouser (incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.895251</td>\n",
       "      <td>-0.234924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.562454</td>\n",
       "      <td>-0.885176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417090</td>\n",
       "      <td>0.271888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.044356</td>\n",
       "      <td>-0.734198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.315568</td>\n",
       "      <td>0.841983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.479091</td>\n",
       "      <td>1.454774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.535020</td>\n",
       "      <td>-0.399175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.773129</td>\n",
       "      <td>-0.957175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.403634</td>\n",
       "      <td>1.396038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.588496</td>\n",
       "      <td>-0.497285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X         Y\n",
       "0  -0.895251 -0.234924\n",
       "1  -1.562454 -0.885176\n",
       "2  -0.417090  0.271888\n",
       "3   1.044356 -0.734198\n",
       "4  -0.315568  0.841983\n",
       "..       ...       ...\n",
       "95  0.479091  1.454774\n",
       "96 -0.535020 -0.399175\n",
       "97 -0.773129 -0.957175\n",
       "98  0.403634  1.396038\n",
       "99 -0.588496 -0.497285\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "portfolio_df = pd.read_csv('Portfolio.csv')\n",
    "display(portfolio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(X,Y):\n",
    "    return ((np.var(Y)-np.cov(X,Y))/(np.var(X)+np.var(Y)-2*np.cov(X,Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating $\\alpha$ using all 100 observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.07270947 0.57665115]\n",
      " [0.57665115 0.06414064]]\n"
     ]
    }
   ],
   "source": [
    "X = portfolio_df.X[0:100]\n",
    "y = portfolio_df.Y[0:100]\n",
    "print(alpha(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next command uses the sample() function to randomly select 100 observations from the range 1 to 100, with replacement. This is equivalent to constructing **one** new bootstrap data set and recomputing  $\\alpha$  based on the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsample = portfolio_df.sample(frac=1, replace=True)\n",
    "X = dfsample.X[0:100]\n",
    "y = dfsample.Y[0:100]\n",
    "print(alpha(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.12314555 0.58054718]\n",
      " [0.58054718 0.09624484]]\n"
     ]
    }
   ],
   "source": [
    "def bstrap(df):\n",
    "    tresult = 0\n",
    "    for i in range(0,1000): #create 1000 bootstrap samples\n",
    "        dfsample = df.sample(frac=1, replace=True) #frac=1 means for each bootstrap, sample the same number as the dataset\n",
    "        X = dfsample.X[0:100]\n",
    "        y = dfsample.Y[0:100]\n",
    "        result = alpha(X,y)\n",
    "        tresult += result\n",
    "    fresult = tresult / 1000\n",
    "    print(fresult)\n",
    "    \n",
    "bstrap(portfolio_df) # returns the average of the 1000 bootstrap samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incomplete....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3a) k-fold cross-validation is implemented by taking the set of n observations and randomly splitting into k non-overlapping groups. Each of these groups acts as a validation set and the remainder as a training set. The test error is estimated by averaging the k resulting MSE estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3bi) Compared to validation set approach where half of training data is turned to validation set, k-fold cross-validation provides better model fit as all the data is used for training. In other words, 1) the estimated test error rate can be high depending on which data is in the training set. 2) The validation set error may overestimate the test error rate for the model fit on the entire data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3bii) Compared to Leave One Out Cross validation (LOOCV), k-fold CV requires much less computation power as the model is only fit k times, typically between 5 and 10, compared to n times when LOOCV is used. Also, LOOCV has higher variance but lower bias than k-fold CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)To estimate the standard deviation of our prediction, we use the bootstrap method (sampling with replacement), where we create many bootstrap samples and for each one we fit a model and compute our response Y prediction. We then take the standard deviation of the many Y predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
